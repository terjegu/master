\chapter{Results} % (fold)
\label{cha:results}

% some introduction...
% 
% \section{Pitch and voiced/unvoiced detection} % (fold)
% \label{sec:pitch_and_voiced_unvoiced_detection}
% 
% 
% 
% 
% % section Pitch and voiced/unvoiced detection (end)


\section{Fundamental Frequency Transformation} % (fold)
\label{sec:fundamental_frequency_ransformation}
The smoothing techniques for the frequency transform was tested in a controlled environment with the target cepstrum as input, not included in the training set however. The transformation used a 64 mixture GMM with full covariance matrices and was trained with 100 sentences where the unvoiced frames were discarded, yielding a total of 33~000 training vectors. The results from the different smoothing techniques are presented in Table~\ref{tab:pitch_pred_target_input}. NPD values greater than 1 means that the source pitch is closer to the target pitch than the transformed pitch. The standard deviation of the error by using a scaled source pitch is $23.38$ Hz.
\begin{table}[htbp]
	\begin{center}
		\topcaption{$f_0$ transformation with target cepstrum vectors as input for 10 sentences.}
		\label{tab:pitch_pred_target_input}	
		\begin{tabular}{lrrr}
			\toprule
			\multicolumn{1}{c}{\emph{Method}} & \multicolumn{1}{c}{$\mu_{error}$} & \multicolumn{1}{c}{$\sigma_{error}$} & \multicolumn{1}{c}{\emph{NPD}} \\
			\midrule
			% Source $f_0$ & 24.82 Hz & 23.38 Hz \\
			No smoothing & -0.75 Hz & 20.31 Hz & 0.5959\\
			Moving average & -0.77 Hz & 19.71 Hz & 0.5783 \\
			Modified m-avg & -1.58 Hz & 19.19 Hz & 0.5647 \\
			Delta limit & -1.71 Hz & 19.93 Hz & 0.5865 \\
			\bottomrule			
		\end{tabular}		
	\end{center}
\end{table}

The results are comparable to the findings of T. En-Najjary \etal \cite{najjary03new} and indicates that there is a good correlation between cepstral coefficients and fundamental frequency. Given that the target CC are available, the fundamental frequency transformation works quite well. ``Improved moving average'' has the smallest standard deviation, but the mean error is not as good as the ``moving average'' or the ``no smoothing'' setups. Since the mean error could be set to zero by a scaling, the standard deviation is the most important metric. However, the mean $f_0$ varies a lot from one sentence to another in the original speech signal. So even if a scaling would improve the overall mean error, it will in most cases not enhance the correctness on a sentence by sentence basis. Another drawback by this transformation is that the transformed pitch is more monotone than the original speech. The standard deviation in the $f_0(n)$ sequence of 10 sentences of the transformed $f_0$ is approximately 13 Hz while in the original speech it is about 25 Hz.

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=.85\textwidth]{fig/f0_compare}
		\caption{Typical contour of $f_0$ transformation with different smoothing techniques and target $Y_{cc}$ as input. Target contour marked with red.}
		\label{fig:pitch_trans}
	\end{center}
\end{figure}
Figure~\ref{fig:pitch_trans} depicts the transformed $f_0(t)$ for a test sentence. The transform without smoothing does not appear to be too bad from Table~\ref{tab:pitch_pred_target_input}, but Figure~\ref{fig:pitch_trans} reveals a fluctuating $f_0$ which is not very natural. The smoothing techniques produce a $f_0$ contour which is similar to the correct contour, and in this particular case the moving average with $M=3$ seems to be the best choice.

In a real scenario the available input to the $f_0$ transform is the transformed $\mathbf{\tilde{Y}}_{cc}$ vectors. 
\begin{table}[htbp]
	\begin{center}
		\topcaption{$f_0$ transformation error with transformed cepstral vector as input for 10 sentences.}
		\label{tab:pitch_pred_transformed_input}	
		\begin{tabular}{lrrr}
			\toprule
			\multicolumn{1}{c}{\emph{Method}} & \multicolumn{1}{c}{$\mu_e$} & \multicolumn{1}{c}{$\sigma_e$} & \multicolumn{1}{c}{\emph{NPD}} \\
			\midrule
			% Source pitch & 24.82 Hz & 23.38 Hz\\
			No smoothing & -0.05 Hz  & 26.29 Hz & 0.7709\\
			Moving average & -0.08 Hz  & 24.57 Hz & 0.7206\\
			Modified m-avg & 1.18 Hz & 23.59 Hz & 0.6927\\
			Delta limit & 1.25 Hz & 24.56 Hz & 0.7211 \\
			\bottomrule			
		\end{tabular}		
	\end{center}
\end{table}

This introduces another source of error and the transformation precision is degraded as shown in Table~\ref{tab:pitch_pred_transformed_input}. Again the modified moving average had the lowest standard deviation. The table shows an average result from 10 sentences.

The modified moving average is a moving average filter over three independent transformation of one $f_0(t)$. But is not certain that it is transformations of the same $f_0(t)$ since the value from the previous transformation $f_{0,t-1(n+1)}$ is the $f_0$ that should be the next after the current $f_{0,t}(n)$. When the transformation input are independent transformed cepstral vectors it is not given that consecutive input vectors would appear as consecutive in a real speech segment of the target speaker, hence the three $f_0$ values in the average operation might correspond to quite different pitch periods, unless the cepstral transformation is flawless.

Since there is a correlation between the source cepstrum and the target cepstrum as well as the target cepstrum and the target fundamental frequency, a transformation of target $f_0$ with source cepstrum as input is a worthy alternative. A comparison of transformation with source cepstrum $\mathbf{x}_{cc}$ and transformed cepstrum $\mathbf{\tilde{y}}_{cc}$ as input is shown in Table~\ref{tab:f0_source_transform}
\begin{table}[htbp]
	\begin{center}
		\topcaption{Fundamental frequency transform with source cepstrum as input.}
		\label{tab:f0_source_transform}
		\begin{tabular}{lrrr}
			\toprule
			\multicolumn{1}{c}{\emph{Method}} & \multicolumn{1}{c}{\emph{$\mu_e$}} & \multicolumn{1}{c}{\emph{$\sigma_e$}} & \multicolumn{1}{c}{\emph{NPD}}\\
			\midrule
			Transformed cepstrum & -0.05 Hz & 26.29 Hz & 0.7709\\
			Source cepstrum & -2.93 Hz & 22.63 Hz & 0.6690\\
			\bottomrule			
		\end{tabular}		
	\end{center}	
\end{table}

To relax the computational complexity, the fundamental frequency can be transformed together with the spectrum as a joint vector $\mathbf{z} = \sbrackets{\mathbf{x}_{cc},\mathbf{y}_{cc},f_0}$. Table~\ref{tab:f0_joint_transform} shows a comparison to the standalone transformation with transformed cepstrum vectors as input and the joint transformation.
\begin{table}[htbp]
	\begin{center}
		\topcaption{Joint fundamental frequency and spectrum transformation}
		\label{tab:f0_joint_transform}
		\begin{tabular}{lrrr}
			\toprule
			\multicolumn{1}{c}{\emph{Method}} & \multicolumn{1}{c}{\emph{$\mu_e$}} & \multicolumn{1}{c}{\emph{$\sigma_e$}} & \multicolumn{1}{c}{\emph{NPD}}\\
			\midrule
			Standalone & -0.05 Hz & 26.29 Hz & 0.7709\\
			Joint transform & -3.43 Hz & 22.26 Hz & 0.6605\\
			\bottomrule			
		\end{tabular}		
	\end{center}	
\end{table}
Table~\ref{tab:f0_joint_transform} shows that the joint transformation decreases the standard deviation, but increases the mean error. 

Although the transformations presented yields a nearly perfect average fundamental frequency, the prosody in a transformed sentence are not necessary correct. It could, however, be improved by certain ad-hoc adjustments. The transformation in hand is clearly not context dependent. If the context was known the $f_0$ contour could be scaled, with \eg a parabola for a typical statement, to enhance the performance. Without context information this is impossible since the prosody in a statement is clearly different than in a question. The source $f_0$ could be used in the transformation to introduce some context awareness. 

As mentioned above, the mean error could be dealt with by a scaling which means that the joint transformation with source cepstrum as input with modified moving average smoothing, yields the best transformation with the GMM and test sentences in question.
% section Fundamental Frequency Transformation (end)

\section{Frequency Spectrum Transformation} % (fold)
\label{sec:frequency_transformation}
The frequency transformation was done in the cepstrum domain. A 128 mixture GMM with diagonal covariance matrices was trained with the same training senteces as the $f_0$ transformation. Four different setups were tested and the average results of the Itakura distance \eqref{eq:itakura_distance}, the $L_2$ metric \eqref{eq:l2_metric} and the cepstral distance \eqref{eq:cepstral_distance} of 10 sentences are shown in Table~\ref{tab:absolute_freq_results}. The distances of the source and target feature vectors before transformation are; itakura = 0.6053, $L_2$ = 4.4985 and CD = 0.4483. An ideal transformation would yield 0 for all metrics.
\begin{table}[htbp]
	\begin{center}
		\topcaption{Absolute error in frequency transformation.}
		\label{tab:absolute_freq_results}
		\begin{tabular}{lrrr}
			\toprule
			\multicolumn{1}{c}{\emph{Setup}} & \multicolumn{1}{c}{\emph{Itakura}} & \multicolumn{1}{c}{\emph{$L_2$}} & \multicolumn{1}{c}{\emph{CD}}\\
			\midrule
			Normal &  0.4479 & 3.5603 & 0.2629 \\
			Pre-emphasis & 0.5235 & 3.8603 & 0.2947 \\
			$c_0$ excluded & 0.5199 & 3.9065 & 0.3140 \\
			Pre-emph and $c_0$ excluded & 0.6066 & 4.2411 & 0.3241 \\
			\bottomrule			
		\end{tabular}		
	\end{center}	
\end{table}

% \begin{table}[htbp]
% 	\begin{center}
% 		\topcaption{Absolute error in frequency transformation.}
% 		\label{tab:absolute_results}
% 		\begin{tabular}{lrrrr}
% 			\toprule
% 			\multicolumn{1}{c}{\emph{Setup}} & \multicolumn{1}{c}{\emph{Itakura pre}} & \multicolumn{1}{c}{\emph{Itakura post}} & \multicolumn{1}{c}{\emph{$L_2$ pre}} & \multicolumn{1}{c}{\emph{$L_2$ post}}\\
% 			\midrule
% 			Normal & 0.6053 & 0.4652 & 4.4985 & 3.7524 \\
% 			Pre-emphasis & 0.7925 & 0.5127 & 5.2366 & 3.9638 \\
% 			$c_0$ excluded &  0.6053 & 0.5267 & 4.4985 & 4.1227 \\
% 			Pre-emph and $c_0$ excluded & 0.7925 & 0.6038 & 5.2366 & 4.4277 \\
% 			\bottomrule			
% 		\end{tabular}		
% 	\end{center}	
% \end{table}


A different point of view is the relative improvement to the starting point. The normalised results are shown in Table~\ref{tab:normalised_freq_results} for the same 10 sentences. By implementing pre-emphasis the source and target spectra are also affected which does not justify the absolute results of the pre-emphasis transform. The relative distance measures is therefor a better metric in this regard.
\begin{table}[htbp]
	\begin{center}
		\topcaption{Normalised error in frequency transformation.}
		\label{tab:normalised_freq_results}
		\begin{tabular}{lrrr}
			\toprule
			\multicolumn{1}{c}{\emph{Setup}} & \multicolumn{1}{c}{\emph{N-Itakura}} & \multicolumn{1}{c}{\emph{N-L$_2$}} & \multicolumn{1}{c}{\emph{NCD}}\\
			\midrule
			Normal & 0.7385 & 0.2307 & 0.64354 \\
			Pre-emphasis &  0.6921 & 0.2206 & 0.6131 \\
			$c_0$ excluded & 0.8573 & 0.2507 & 0.7687 \\
			Pre-emph and $c_0$ excluded & 0.8020 & 0.2382 & 0.6743 \\
			\bottomrule			
		\end{tabular}		
	\end{center}	
\end{table}
The different techniques does not appear to have a positive effect on the performance compared to the straight forward transformation. By excluding the energy coefficient $c_0$ some of the prosody are taken out of the question. While this might be a good choice for a transformation meant for dubbing or other applications where the source speaker tried to impostor a target speaker, it is of no help in a general transformation.

The motivation for applying pre-emphasis is to enhance the transformation quality in high frequencies.
\begin{figure}[htbp]
	\begin{center}
	\subfigure[Without pre-emphasis]{\label{fig:freq_100}
		\includegraphics[width=\matlabfour]{fig/freq_15}}
	\subfigure[Pre-emphasis applied]{\label{fig:freq_100_pre}
		\includegraphics[width=\matlabfour]{fig/freq_15_pre}}
	\subfigure[Without pre-emphasis]{\label{fig:freq_125}
		\includegraphics[width=\matlabfour]{fig/freq_125}}
	\subfigure[Pre-emphasis applied]{\label{fig:freq_125_pre}
		\includegraphics[width=\matlabfour]{fig/freq_125_pre}}
	\caption{The effect of pre-emphasis on magnitude spectrum.}
	\label{fig:pre_emphasis_magnitude_spectrum}
	\end{center}
\end{figure}
As depicted in Figure~\ref{fig:pre_emphasis_magnitude_spectrum} this does not appear to be necessary. Transformed spectrum does not have a higher error in the high frequencies than in the low frequencies, Figure~\ref{fig:freq_100} and \ref{fig:freq_125}. With pre-emphasis applied the overall error is only increased, Figure~\ref{fig:freq_100_pre} and \ref{fig:freq_125_pre}.

The setup with the best performance was the straight forward implementation without pre-emphasis and including the energy coefficient $c_0$. The average density of the LPC coefficients from 10 sentences, excluding the first which was 1 for all vectors, yielding a total of 28 000 parameters, are depicted in Figure~\ref{fig:hist_lp}.
% \begin{figure}[htbp]
% 	\begin{center}
% 		\includegraphics[width=.8\textwidth]{fig/hist_lp}
% 		\caption{Comparison of LP parameters distributions.}
% 		\label{fig:hist_lp}
% 	\end{center}
% \end{figure}
\begin{figure}[htbp]
	\begin{center}
	\subfigure[Source LP]{\label{fig:hist_source}
		\includegraphics[width=\matlabthree]{fig/hist_source}}
	\subfigure[Target LP]{\label{fig:hist_target}
		\includegraphics[width=\matlabthree]{fig/hist_target}}
	\subfigure[Transformed LP]{\label{fig:hist_conv}
		\includegraphics[width=\matlabthree]{fig/hist_conv}}
	\caption{Comparison of LP parameters distributions.}
	\label{fig:hist_lp}
	\end{center}
\end{figure}
The source Figure~\ref{fig:hist_source} and target LP coefficients Figure~\ref{fig:hist_target} are almost evenly distributed, while the distribution of the converted coefficients Figure~\ref{fig:hist_conv} differ from the target distribution. The target distribution is more narrow than the source distribution, and the transformed distribution reflects these differences but a bit too much. Even though they have the same mean value, the converted parameters has a more narrow distribution and are dense in different regions than the target distribution.

Table~\ref{tab:spectrum_joint_transform} shows a comparison on the spectrum transformation of joint and standalone transformation.
\begin{table}[htbp]
	\begin{center}
		\topcaption{Comparison of standalone and joint spectrum transformation}
		\label{tab:spectrum_joint_transform}
		\begin{tabular}{lrrr}
			\toprule
			\multicolumn{1}{c}{\emph{Method}} & \multicolumn{1}{c}{\emph{Itakura}} & \multicolumn{1}{c}{\emph{$L_2$}} & \multicolumn{1}{c}{\emph{CD}}\\
			\midrule
			Standalone & 0.4565 & 3.6852 & 0.2939 \\
			Joint transform & 3.2840 & 10.157 & 3.0131 \\
			\bottomrule			
		\end{tabular}		
	\end{center}	
\end{table}
The joint transform did not have a dramatic effect on the $f_0$ transform, in fact it had a lower standard deviation than the standalone transform. But the joint transformation of the spectrum is even worse than no transformation at all. The joint transformation should therefor only be used to transform the pitch with the frequency transform done separately.

Table~\ref{tab:absolute_freq_results} and Figure~\ref{fig:hist_lp} shows that the transformation is not perfect. It was off course not foreseen to be either, but it could be better by using more mixtures in the GMM. By using more mixtures in the GMM would also require more training vectors for the fitting algorithm (EM) to converge. This is not always practically possible, but is would increase the performance as shown in the research of Y. Stylianou \etal \cite{stylianou98}. 100 training vectors, as used in this implementation, is already a lot to ask of a ``source speaker'' in many cases. E. Helander \etal \cite{helander08} proposed a different approach with a very small training set. By using line spectral frequencies (LSF) and exploiting their intra-frame correlations, a separate GMM could be created for each source speaker LSF element and the target LSF elements which best correlate with the current source LSF element. Yielding one full covariance GMM for each LSF element with vectors of only a few elements and only a few mixtures required for good transformation results.
% section Frequency Transformation (end)

\section{Listening Test} % (fold)
\label{sec:listening_test}
10 sentences with random choice of source and target speaker was transformed and presented to a test group of 15 students. The test persons were asked which speaker they thought the transformed speech belonged to. If the transformed speech was recognised as the target speaker the the answer was noted as correct. The test persons were also given the choice of no distinctive recognition. The results are presented in Table~\ref{tab:subjective_listening_results}.
\begin{table}[htbp]
	\begin{center}
		\topcaption{Subjective listening results.}
		\label{tab:subjective_listening_results}
		\begin{tabular}{ccc}
			\toprule
			\multicolumn{1}{c}{\emph{Correct recognition}} & \multicolumn{1}{c}{\emph{Wrong recognition}} & \multicolumn{1}{c}{\emph{No recognition}}\\
			\midrule
			72 \% & 22 \% & 6 \% \\
			\bottomrule			
		\end{tabular}		
	\end{center}	
\end{table}
A more detailed test score matrix could be found in Appendix~\ref{cha:individual_listening_test_score}.

The small differences in the objective results of the frequency transformation were reflected as even smaller differences in the synthesised voice. A bad frequency transformation was tested, \ie few training vectors and small number of GMM mixtures, and yielded noise artefacts in the synthesised signal. However, the differences in the final setups had negligible differences in the synthesised signal. Nevertheless, there are no significant disadvantages in choosing the best setup.

The pitch transform benefitted from the smoothing techniques, but it was small differences between the smoothing techniques. Synthesised voice without smoothing applied was less natural than with smoothing. Even though the average error in the transformed $f_0$ was about zero, the standard deviation was almost 25 Hz which resulted in a mean error in one of the test sentences was as high as 35 Hz which where definitively noticeable.

The results in Table~\ref{tab:subjective_listening_results} are promising, but the test person were only given two choices really. If there were presented with several possible target voices, the results would probably be a lot worse. The major shortcomings of this transformation implementation is the lack of time-scale modifications. There is some time-scale modification in the PSOLA with the transformed pitch, but pitch cycles are not discarded or duplicated. Meaning that the number of pitch periods are the same for the source speaker and the transformed voice. The test voices in the subjective test differed in a lot of aspects. The mean fundamental frequency differed by almost 30 Hz and the length in seconds of the same sentence differed on average by 20 \%. It seemed to be easy to detect the correct voice if only concentrating on the pitch, and also the pronunciation of words seemed recognisable. But the fact that the length of a sentence was not modified enough was the huge source of recognition error. This was especially noticeable in transformation from the slow low-pitched voice to the faster speaker with a higher pitch. It might be possible to implement duplications and discarding of frames in the dynamic time warping. The statistical data for which frames to discard or duplication might be collected from the DTW when one feature frame is mapped to more than one frame. The number of source frames are not modified in the current implementation.


% section Listening Test (end)
% chapter Results (end)